---
bg: photo023.jpg
layout: post
title: Fast Human Pose Estimation
crawlertitle: FPD
summary: Fast Human Pose Estimation
date: 2019-08-30 20:00:00 +0800
categories: paper
tags: HPE
author: vpromise
---

*Paper Reading: Fast Human Pose Estimation*

---

- [Fast Human Pose Estimation](#fast-human-pose-estimation)
  - [介绍](#介绍)
  - [贡献](#贡献)
  - [方法](#方法)
    - [知识蒸馏 (Knowledge Distillation)](#知识蒸馏-knowledge-distillation)
    - [网络结构](#网络结构)
  - [实验](#实验)
  - [总结](#总结)

# Fast Human Pose Estimation

这篇文章是电子科技大学和 Vision Semantics 共同完成的,关注于构建一个轻量化的人体姿态估计模型,在保证精度的同时提高模型效率,是一个偏向于应用层面的研究。

## 介绍

现有的人体姿态估计方法往往只考虑如何提高模型的泛化性能,而忽略了效率问题,导致重型模型很难在实际中使用。本文提出了一种新的快速姿态蒸馏(Fast Pose Distillation , FPD) 模型学习策略,训练能够以低计算成本快速执行的轻量级姿态神经网络结构。

## 贡献
本文的主要贡献可以总结为以下三点:
1. 研究了人体姿态估计模型效率问题,有助于将现有深度姿态估计方法扩展到实际应用。
2. 提出 Fast Pose Distillation (FPD) 模型训练方法,能够更有效地训练超小型人体姿态神经网络。
3. 设计了一个轻量级 Hourglass 网络,在提升成本效益同时保持足够准确率。

## 方法
### 知识蒸馏 (Knowledge Distillation)
知识蒸馏的概念由 Hinton 在他的文章Distilling the Knowledge in a Neural Network 中首次提出，简要总结为通过教师网络 (teacher network) 输出作为 soft label 来训练一个学生网络 (student network) ，实现知识迁移。
### 网络结构
文章采用快速姿态提取模型学习策略，整体框架如图1所示。首先训练一个大型教师姿态估计模型，本文采用原始沙漏模型。然后借助教师模型所学到的知识来训练目标学生模型，论文中学生网络为轻量级沙漏网络，训练时，教师网络为学生网络提供额外的监督指导，知识蒸馏便发生在这一过程中。在测试时，轻量学生姿态估计模型便能够实现快速且经济高效的部署，而计算量很大的教师模型最终被丢弃，因为它的辨别知识已经转移到目标模型中。
![图1 快速姿态提取模型学习策略](https://i.loli.net/2019/09/01/zX2pQdVLr8gWCNO.png)
<center>图3.1 快速姿态提取模型学习策略</center>

为能够有效地将教师网络的知识转移到学生模型的训练，本文设计一个合适的损失函数, 总体损失函数由姿态蒸馏损失函数和均方差损失函数组成，并通过系数α平衡两者。最终便可让网络结合 ground-truth 和教师模型的预测结果来进行训练。

![1](https://i.loli.net/2019/09/01/IEcROtwbu6h2orU.png)
![2](https://i.loli.net/2019/09/01/ON9eghZ4zlIYExi.png)
![3](https://i.loli.net/2019/09/01/X8kibEhQRr9zVWd.png)

关于教师网络的有效性，可作如下的解释
1. 人工标记的关节点坐标标签可能存在一定错误，教师模型能够通过学习和推理来减少一些错误，从而减少错误标记的训练样本的误导。
2. 在复杂背景和遮挡情形下，教师模型可以通过用模型推理解释这些困难点，从而降低学习难度。
3. 无标记关节点坐标可能会被教师网络标记。

## 实验
作者在MPII和LSP数据集上进行了实验，所提出的FPD 方法都取得了与最好结果可比较的精度。表1 展示了在MPII数据集上的测试结果，发现 FPD 模型size只有3M，计算复杂度也大幅降低，而且没有出现明显的模型泛化能力降低，在 LSP 数据集上也展现了同样的结果。同时作者也对 loss 函数的选择和 loss 函数中平衡系数的选择做了实验验证，确定了论文中 loss 函数的选择是最佳的。还做了实验验证了 knowledge distillation 的方法对最终精度有提升。这部分的实验不算复杂，在此就不作过多展示。
<center>表1 PCKh@0.5and AUC (%) rates on the MPII test dataset</center>

![表1 PCKh@0.5and AUC (%) rates on the MPII test dataset](https://i.loli.net/2019/09/01/hOjPxC2GJ4qWrNi.png)

## 总结
本文提出了一种新的快速姿态提取学习策略。与大多数现有的人体姿态估计方法相比，FPD旨在解决研究不足和实际意义重大的模型成本效益质量问题，以便将人体姿态估计模型扩展到现实中的大规模部署。
总体来说，论文的出发点确实是很有意义且很有必要，现在的深度学习方法确实大幅提高了很多计算机视觉任务中的精度，但同时模型也越来越复杂，导致了不能很好的应用到轻量级的设备上，使理论研究与工业应用不能很好的结合。轻量快速高效的网络也会一直是一个值得研究的方向。
论文中 knowledge distillation 的概念听着很高端，但实际应用并不复杂。而文中设计的新的 loss 函数也只是简单的将 teacher network 的输出作为 label 计算 loss，与传统的姿态估计的 loss 计算方法没有差别，将两个 loss 相结合以及研究平衡系数还是值得借鉴，总的来说这个损失函数的设计其实是很自然的。
文章中 teacher network 选用 Hourglass 网络，student network模型的构造也很直接，直接将Hourglass模型缩小一倍，将8个stage 缩小为4个, conv层通道数从256减小到128。虽然实验中对不同 Stage 数和 Channel 数的模型都做了对比试验分析，但如果考虑其他网络结构的小模型作为 student network ，而不仅限于 Hourglass 网络，不知道效果会不会有提升。还有论文一直强调参数少消耗低，这仅针对最终的 student network， 但是整个流程还是需要先训练一个复杂的 teacher network，而这部分的资源消耗和网络复杂度作者却未提及。