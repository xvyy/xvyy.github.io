---
bg: "photo36.jpg"
layout: post
title: "3D HPM with SSL"
crawlertitle: "3D Human Pose Machines with Self-supervised Learning"
summary: "3D Human Pose Machines with Self-supervised Learning"
date: 2019-12-20 11:00:00 +0800
categories: "paper"
tags: "HPE"
author: "vpromise"
---

*This paper proposes a simple yet effective self-supervised correction mechanism to learn all intrinsic structures of human poses from abundant images*

---

- [Abstrsact](#abstrsact)
  - [Contributions](#contributions)
- [3D Human Pose Machine](#3d-human-pose-machine)
  - [Framework](#framework)
  - [Model Training](#model-training)
- [Experiments](#experiments)
  - [Quantitative comparisons on the Human3.6M dataset](#quantitative-comparisons-on-the-human36m-dataset)
  - [Quantitative comparisons on the HumanEva-I dataset](#quantitative-comparisons-on-the-humaneva-i-dataset)
  - [Qualitative comparisons on the Human3.6M dataset](#qualitative-comparisons-on-the-human36m-dataset)
  - [Ablation Study](#ablation-study)
- [Conclusion](#conclusion)

---

# Abstrsact

Recovering 3D human poses has become increasingly important. In fact, completing this task is quite challenging due to the diverse appearances, viewpoints, occlusions and inherently geometric ambiguities inside monocular images.
Attempt to address this issue, this paper proposes a simple yet effective self-supervised correction mechanism to learn all intrinsic structures of human poses from abundant images. Specifically, the proposed mechanism involves two dual learning tasks, i.e., the 2D-to-3D pose transformation and 3D-to-2D pose projection, to serve as a bridge between 3D and 2D human poses in a type of “free” self-supervision for accurate 3D human pose estimation.

## Contributions
- Present a novel model that learns to integrate rich spatial and temporal long-range dependencies as well as 3D geometric constraints, rather than relying on specific manually defined body smoothness or kinematic constraints;
- Developing a simple yet effective self-supervised correction mechanism to incorporate 3D pose geometric structural information is innovative in literature, and may also inspire other 3D vision tasks;
- The proposed self-supervised correction mechanism enables our model to significantly improve 3D human pose estimation via sufficient 2D human pose data.

# 3D Human Pose Machine

## Framework

![framework](https://i.loli.net/2019/12/20/MAmGBSFv9jlZTgP.png)

We propose a 3D human pose machine to resolve 3D pose sequence generation for monocular frames, and we introduce a concise self-supervised correction mechanism to enhance our model by retaining the 3D geometric consistency.After extracting the 2D pose representation and estimating the 2D poses for each frame via a common 2D pose subnetwork, our model employs two consecutive modules. The first module is the *2D-to-3D pose transformer module* for transforming the 2D pose-aware features from the 2D domain to the 3D domain. This module is designed to estimate intermediate 3D poses for each frame by incorporating temporal dependency in the image sequence. The second module is the *3D-to-2D pose projector module* for bidirectionally refining the intermediate 3D pose prediction via our introduced self-supervised correction mechanism. These two modules are combined in a unified framework to be optimized in a fully end-to-end manner.

An overview of the proposed 3D human pose machine framework is show in the above picture. Our model predicts the 3D human poses for the given monocular image frames, and it progressively refines its predictions with the proposed self-supervised correction. Specifically, the estimated 2D pose $p_t^{2d}$ with the corresponding pose representation$f_t^{2d}$ for each frame of the input sequence is first obtained and further passed into two neural network modules: i) a 2D-to-3D pose transformer module for transforming the pose representations from the 2D domain to the 3D domain to intermediately predict the 2d human joints $p_t^{3d}$ in the 3D coordinates, and ii) a 3D-to-2D pose projector module to obtain the projected 2D pose $p̂_t^{2d}$ after regressing $p_t^{3d}$ into $p̂_t^{3d}$. Through minimizing the difference between $p_t^{2d}$ and $p̂_t^{2d}$, our model is capable of bidirectionally refining the regressed 3D poses $p_t^{3d}$ via the proposed self-supervised correction mechanism. Note that the parameters of the 2D-to-3D pose transformer module for all frames are shared to preserve the temporal motion coherence. 3K and 2K denotes the dimension of the vector for representing the 3D and 2D human pose formed by K skeleton joints, respectively.

Please chech the paper for more detial information of the 2D Pose Sub-network, 2D-to-3D Pose Transformer Module and 3D-to-2D Projector Module, please chech the paper.

![3D to 2D](https://i.loli.net/2019/12/20/sEaWAh8VmcCQuvL.png)

## Model Training

![algorithm](https://i.loli.net/2019/12/20/RLEFyuPhl3Z6gtJ.png)

Since our model consists of two cascaded modules, the training phase can be divided into the following steps: (i) Initialize the 2D pose representation via pre-training. To obtain a satisfactory feature representation, the 2D pose sub-network is first pre-trained with the MPII Human Pose dataset, which includes a larger variety of 2D pose data. (ii) Initialize the 2D-to-3D pose transformer module. We fix the parameters of the 2D pose sub-network and optimize the network parameter. (iii) Initialize the 3D-to-2D pose projector module. We fix the above optimized parameters and optimize the network parameter. (iv) Fine-tune the whole model jointly to further update the network parameters with the 2D pose and 3D pose training data.

# Experiments

## Quantitative comparisons on the Human3.6M dataset
The entries with the smallest 3D pose errors for each category are bold-faced. A method with “*” denotes that it is individually trained on each action category. Our model achieves a significant improvement over all compared approaches. 

![1](https://i.loli.net/2019/12/20/8BD1MLwZjab9zOi.png)

## Quantitative comparisons on the HumanEva-I dataset

Quantitative comparisons on the HumanEva-I dataset using 3D pose errors (in illimeters) for the “walking”, “jogging” and “boxing” sequences.’-’ indicates that the author of the corresponding method did not report the accuracy on that action. The entries with the smallest 3D pose errors for each category are bold-faced. Our model outperforms all the compared methods by a clear margin.

![2](https://i.loli.net/2019/12/20/ULY3lyZ1g2jbAiD.png)

## Qualitative comparisons on the Human3.6M dataset

The 3D poses are visualized from the side view, and the cameras are depicted. our model and the ground truth are illustrated from left to right. Our model achieves considerably more accurate estimations than all the compared methods. Best viewed in color. Red and green indicate left and right, respectively.

![3](https://i.loli.net/2019/12/20/oleGcRNOVgrbmH1.png)

## Ablation Study

- Self-supervised Correction Mechanism
- Temporal Dependency
- External 2D Human Pose Data

![4](https://i.loli.net/2019/12/20/wqExHdcFirYyovZ.png)

# Conclusion
This paper presented a 3D human pose machine that can learn to integrate rich spatio-temporal long-range dependencies and 3D geometry knowledge in an implicit and comprehensive manner. We further enhanced our model by developing a novel self-supervised correction mechanism,which involves two dual learning tasks, i.e., 2D-to-3D pose transformation and 3D-to-2D pose projection, under a self-supervised correction mechanism. This mechanism retains the geometric consistency between the 2D projections of 3D poses and the estimated 2D poses, and it enables our model to utilize the estimated 2D human pose to bidirectionally refine the intermediate 3D pose estimation. Therefore, our proposed self-supervised correction mechanism can bridge the domain gap between 3D and 2D human poses to leverage the external 2D human pose data without requiring additional 3D annotations. Extensive evaluations on two public 3D human pose datasets validate the effectiveness and superiority of our proposed model. In future work, focusing on sequence-based human centric analyses (e.g., human action and activity recognition), we will extend our proposed self-supervised correction mechanism for temporal relationship modeling, and design new self-supervision objectives to incorporating abundant 3D geometric knowledge for training models in a cost-effective manner.

- [back to top](#abstrsact)